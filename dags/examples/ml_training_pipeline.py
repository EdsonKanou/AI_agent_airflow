"""
DAG de Pipeline Machine Learning.

Ce DAG illustre :
- EntraÃ®nement de modÃ¨le scikit-learn
- Ã‰valuation et validation
- Branchement conditionnel selon performance
- Sauvegarde de modÃ¨le avec versioning
"""

from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator, BranchPythonOperator
from airflow.operators.bash import BashOperator
from airflow.operators.dummy import DummyOperator
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score
import pickle
import json
import os


def load_and_prepare_data(**context):
    """
    Charger et prÃ©parer les donnÃ©es pour l'entraÃ®nement.
    
    Exemple avec le dataset Iris (remplacer par vos vraies donnÃ©es).
    """
    print("ğŸ“Š Chargement des donnÃ©es...")
    
    # Charger le dataset
    data = load_iris()
    X, y = data.data, data.target
    
    print(f"âœ… {len(X)} Ã©chantillons chargÃ©s")
    print(f"ğŸ“ˆ Features : {data.feature_names}")
    
    # Split train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    # Sauvegarder temporairement
    data_dir = "/tmp/ml_pipeline"
    os.makedirs(data_dir, exist_ok=True)
    
    with open(f"{data_dir}/train_data.pkl", 'wb') as f:
        pickle.dump((X_train, y_train), f)
    
    with open(f"{data_dir}/test_data.pkl", 'wb') as f:
        pickle.dump((X_test, y_test), f)
    
    context['ti'].xcom_push(key='data_dir', value=data_dir)
    context['ti'].xcom_push(key='train_size', value=len(X_train))
    
    print(f"ğŸ’¾ DonnÃ©es sauvegardÃ©es dans {data_dir}")
    
    return data_dir


def train_model(**context):
    """
    EntraÃ®ner le modÃ¨le de machine learning.
    """
    ti = context['ti']
    data_dir = ti.xcom_pull(task_ids='load_data', key='data_dir')
    
    print("ğŸ¤– EntraÃ®nement du modÃ¨le...")
    
    # Charger les donnÃ©es d'entraÃ®nement
    with open(f"{data_dir}/train_data.pkl", 'rb') as f:
        X_train, y_train = pickle.load(f)
    
    # CrÃ©er et entraÃ®ner le modÃ¨le
    model = RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        random_state=42
    )
    
    model.fit(X_train, y_train)
    
    print("âœ… ModÃ¨le entraÃ®nÃ©")
    
    # Sauvegarder le modÃ¨le
    model_path = f"{data_dir}/model.pkl"
    with open(model_path, 'wb') as f:
        pickle.dump(model, f)
    
    ti.xcom_push(key='model_path', value=model_path)
    
    return model_path


def evaluate_model(**context):
    """
    Ã‰valuer les performances du modÃ¨le.
    
    Retourne les mÃ©triques (accuracy, F1-score).
    """
    ti = context['ti']
    data_dir = ti.xcom_pull(task_ids='load_data', key='data_dir')
    model_path = ti.xcom_pull(task_ids='train_model', key='model_path')
    
    print("ğŸ“Š Ã‰valuation du modÃ¨le...")
    
    # Charger le modÃ¨le et les donnÃ©es de test
    with open(model_path, 'rb') as f:
        model = pickle.load(f)
    
    with open(f"{data_dir}/test_data.pkl", 'rb') as f:
        X_test, y_test = pickle.load(f)
    
    # PrÃ©dictions
    y_pred = model.predict(X_test)
    
    # Calculer les mÃ©triques
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='weighted')
    
    metrics = {
        'accuracy': float(accuracy),
        'f1_score': float(f1),
        'test_samples': len(X_test)
    }
    
    print(f"ğŸ“ˆ Accuracy : {accuracy:.4f}")
    print(f"ğŸ“ˆ F1-Score : {f1:.4f}")
    
    # Sauvegarder les mÃ©triques
    metrics_path = f"{data_dir}/metrics.json"
    with open(metrics_path, 'w') as f:
        json.dump(metrics, f, indent=2)
    
    ti.xcom_push(key='metrics', value=metrics)
    ti.xcom_push(key='accuracy', value=accuracy)
    
    return metrics


def check_model_performance(**context):
    """
    DÃ©cider si le modÃ¨le est assez bon pour la production.
    
    Retourne le task_id de la branche Ã  suivre.
    """
    ti = context['ti']
    accuracy = ti.xcom_pull(task_ids='evaluate_model', key='accuracy')
    
    ACCURACY_THRESHOLD = 0.90  # 90%
    
    print(f"ğŸ” Accuracy : {accuracy:.4f} | Seuil : {ACCURACY_THRESHOLD}")
    
    if accuracy >= ACCURACY_THRESHOLD:
        print("âœ… ModÃ¨le acceptable â†’ DÃ©ploiement")
        return 'deploy_model'
    else:
        print("âŒ ModÃ¨le insuffisant â†’ Notification")
        return 'send_failure_alert'


def deploy_model(**context):
    """
    DÃ©ployer le modÃ¨le en production.
    
    Simule le dÃ©ploiement (copie vers un rÃ©pertoire de production).
    """
    ti = context['ti']
    model_path = ti.xcom_pull(task_ids='train_model', key='model_path')
    metrics = ti.xcom_pull(task_ids='evaluate_model', key='metrics')
    
    print("ğŸš€ DÃ©ploiement du modÃ¨le...")
    
    # CrÃ©er un nom versionnÃ©
    version = datetime.now().strftime('%Y%m%d_%H%M%S')
    prod_dir = "/tmp/models_production"
    os.makedirs(prod_dir, exist_ok=True)
    
    prod_model_path = f"{prod_dir}/model_v{version}.pkl"
    
    # Copier le modÃ¨le
    import shutil
    shutil.copy(model_path, prod_model_path)
    
    # Sauvegarder les mÃ©tadonnÃ©es
    metadata = {
        'version': version,
        'deployed_at': datetime.now().isoformat(),
        'metrics': metrics,
        'model_path': prod_model_path
    }
    
    with open(f"{prod_dir}/metadata_v{version}.json", 'w') as f:
        json.dump(metadata, f, indent=2)
    
    print(f"âœ… ModÃ¨le dÃ©ployÃ© : {prod_model_path}")
    print(f"ğŸ“Š Accuracy : {metrics['accuracy']:.4f}")
    
    return prod_model_path


def send_failure_alert(**context):
    """
    Envoyer une alerte si le modÃ¨le n'est pas assez performant.
    """
    ti = context['ti']
    metrics = ti.xcom_pull(task_ids='evaluate_model', key='metrics')
    
    print("âš ï¸  ALERTE : ModÃ¨le insuffisant")
    print(f"ğŸ“Š Metrics : {metrics}")
    print("ğŸ“§ Envoi d'une notification Ã  l'Ã©quipe ML...")
    
    # En production : envoyer un vrai email ou Slack
    
    return "Alert sent"


# === DÃ©finition du DAG ===

default_args = {
    'owner': 'ml_team',
    'depends_on_past': False,
    'email': ['ml-team@company.com'],
    'email_on_failure': True,
    'retries': 1,
    'retry_delay': timedelta(minutes=10),
}

with DAG(
    dag_id='ml_training_pipeline',
    default_args=default_args,
    description='ML pipeline: train, evaluate, deploy based on performance',
    schedule_interval='0 3 * * 0',  # Tous les dimanches Ã  3h
    start_date=datetime(2024, 1, 1),
    catchup=False,
    tags=['ml', 'training', 'sklearn', 'production'],
) as dag:
    
    # TÃ¢che 1 : Chargement des donnÃ©es
    load_data = PythonOperator(
        task_id='load_data',
        python_callable=load_and_prepare_data,
    )
    
    # TÃ¢che 2 : EntraÃ®nement
    train = PythonOperator(
        task_id='train_model',
        python_callable=train_model,
    )
    
    # TÃ¢che 3 : Ã‰valuation
    evaluate = PythonOperator(
        task_id='evaluate_model',
        python_callable=evaluate_model,
    )
    
    # TÃ¢che 4 : Branchement conditionnel
    check_performance = BranchPythonOperator(
        task_id='check_model_performance',
        python_callable=check_model_performance,
    )
    
    # TÃ¢che 5a : DÃ©ploiement (si bon)
    deploy = PythonOperator(
        task_id='deploy_model',
        python_callable=deploy_model,
    )
    
    # TÃ¢che 5b : Alerte (si mauvais)
    alert = PythonOperator(
        task_id='send_failure_alert',
        python_callable=send_failure_alert,
    )
    
    # TÃ¢che 6 : Point de convergence
    end = DummyOperator(
        task_id='end_pipeline',
        trigger_rule='none_failed_min_one_success'  # Continue si au moins une branche rÃ©ussit
    )
    
    # DÃ©pendances
    load_data >> train >> evaluate >> check_performance
    check_performance >> [deploy, alert] >> end